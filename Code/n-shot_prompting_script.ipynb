{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "819b7bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ollama\n",
      "  Downloading ollama-0.5.4-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting httpx>=0.27 (from ollama)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: pydantic>=2.9 in c:\\users\\annie\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ollama) (2.11.7)\n",
      "Collecting anyio (from httpx>=0.27->ollama)\n",
      "  Using cached anyio-4.10.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: certifi in c:\\users\\annie\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx>=0.27->ollama) (2025.7.14)\n",
      "Collecting httpcore==1.* (from httpx>=0.27->ollama)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: idna in c:\\users\\annie\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx>=0.27->ollama) (3.10)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx>=0.27->ollama)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\annie\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic>=2.9->ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\annie\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic>=2.9->ollama) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\annie\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic>=2.9->ollama) (4.14.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\annie\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic>=2.9->ollama) (0.4.1)\n",
      "Collecting sniffio>=1.1 (from anyio->httpx>=0.27->ollama)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Downloading ollama-0.5.4-py3-none-any.whl (13 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached anyio-4.10.0-py3-none-any.whl (107 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: sniffio, h11, httpcore, anyio, httpx, ollama\n",
      "\n",
      "   ------ --------------------------------- 1/6 [h11]\n",
      "   ------ --------------------------------- 1/6 [h11]\n",
      "   ------ --------------------------------- 1/6 [h11]\n",
      "   ------ --------------------------------- 1/6 [h11]\n",
      "   ------------- -------------------------- 2/6 [httpcore]\n",
      "   ------------- -------------------------- 2/6 [httpcore]\n",
      "   ------------- -------------------------- 2/6 [httpcore]\n",
      "   ------------- -------------------------- 2/6 [httpcore]\n",
      "   ------------- -------------------------- 2/6 [httpcore]\n",
      "   ------------- -------------------------- 2/6 [httpcore]\n",
      "   ------------- -------------------------- 2/6 [httpcore]\n",
      "   ------------- -------------------------- 2/6 [httpcore]\n",
      "   -------------------- ------------------- 3/6 [anyio]\n",
      "   -------------------- ------------------- 3/6 [anyio]\n",
      "   -------------------- ------------------- 3/6 [anyio]\n",
      "   -------------------- ------------------- 3/6 [anyio]\n",
      "   -------------------- ------------------- 3/6 [anyio]\n",
      "   -------------------- ------------------- 3/6 [anyio]\n",
      "   -------------------- ------------------- 3/6 [anyio]\n",
      "   -------------------- ------------------- 3/6 [anyio]\n",
      "   -------------------- ------------------- 3/6 [anyio]\n",
      "   -------------------------- ------------- 4/6 [httpx]\n",
      "   -------------------------- ------------- 4/6 [httpx]\n",
      "   -------------------------- ------------- 4/6 [httpx]\n",
      "   -------------------------- ------------- 4/6 [httpx]\n",
      "   -------------------------- ------------- 4/6 [httpx]\n",
      "   -------------------------- ------------- 4/6 [httpx]\n",
      "   -------------------------- ------------- 4/6 [httpx]\n",
      "   -------------------------- ------------- 4/6 [httpx]\n",
      "   --------------------------------- ------ 5/6 [ollama]\n",
      "   ---------------------------------------- 6/6 [ollama]\n",
      "\n",
      "Successfully installed anyio-4.10.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 ollama-0.5.4 sniffio-1.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script httpx.exe is installed in 'c:\\Users\\annie\\AppData\\Local\\Programs\\Python\\Python313\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4dcadf3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME         ID              SIZE      MODIFIED    \n",
      "gemma3:1b    8648f39daa8f    815 MB    10 days ago    \n",
      "qwen3:4b     e55aed6fe643    2.5 GB    10 days ago    \n"
     ]
    }
   ],
   "source": [
    "!ollama list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05edad28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f275955a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query_book, query_description, query_vector, examples, n_shots=0):\n",
    "    # Base context\n",
    "    context = \"\"\"You help recommend books to teenagers. You will do this by analyzing the emotion context of the book description and comparing it to the emotion vectors of what different age groups of teenagers prefer in their book descriptions. Here are the average emotion vectors of books that each age group enjoyed:\n",
    "\n",
    "\"12-13\": {'Anger': 5.928, 'Anticipation': 11.774, 'Disgust': 3.710, 'Fear': 10.412, 'Joy': 15.148, 'Sadness': 6.429, 'Surprise': 5.140, 'Trust': 16.259},\n",
    "\n",
    "\"14-15\": {'Anger': 6.907, 'Anticipation': 10.844, 'Disgust': 4.491, 'Fear': 11.033, 'Joy': 14.164, 'Sadness': 7.528, 'Surprise': 4.784, 'Trust': 15.062},\n",
    "\n",
    "\"16-17\": {'Anger': 7.961, 'Anticipation': 12.758, 'Disgust': 4.934, 'Fear': 13.352, 'Joy': 15.926, 'Sadness': 9.764, 'Surprise': 5.474, 'Trust': 16.686},\n",
    "\n",
    "\"18+\": {'Anger': 6.049, 'Anticipation': 10.697, 'Disgust': 3.925, 'Fear': 10.116, 'Joy': 14.021, 'Sadness': 7.400, 'Surprise': 4.871, 'Trust': 16.471}\n",
    "\"\"\"\n",
    "    \n",
    "    # Add few-shot examples\n",
    "    shots = \"\"\n",
    "    for i in range(min(n_shots, len(examples))):\n",
    "        ex = examples[i]\n",
    "        shots += f\"\"\"\n",
    "Here is an example problem and answer:\n",
    "Question: What age group would you recommend the book “{ex['title']}”? Here is the book description: \"{ex['description']}\" Here is the normalized emotion vector of the description: {ex['vector']}\n",
    "Answer: {ex['answer']}\n",
    "\"\"\"\n",
    "    \n",
    "    # Add the actual query\n",
    "    query = f\"\"\"\n",
    "Here is the question the user has provided:\n",
    "What age group would you recommend the book “{query_book}”? Here is the book description: \"{query_description}\" Here is the normalized emotion vector of the description: {query_vector}\n",
    "Respond only with the age group.\n",
    "\"\"\"\n",
    "    \n",
    "    return context + shots + query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d21734c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "def run_ollama(prompt, model=\"gemma3:1b\"):\n",
    "    response = ollama.chat(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return response[\"message\"][\"content\"].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ffdc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "examples_csv = pd.read_csv(\"correct_cosine_with_vectors.csv\")\n",
    "\n",
    "def age_to_group(age):\n",
    "    if 12 <= age < 14:\n",
    "        return \"12-13\"\n",
    "    elif 14 <= age < 16:\n",
    "        return \"14-15\"\n",
    "    elif 16 <= age < 18:\n",
    "        return \"16-17\"\n",
    "    else:\n",
    "        return \"18+\"\n",
    "\n",
    "few_shot_examples = []\n",
    "for _, row in examples_csv.iterrows():\n",
    "    few_shot_examples.append({\n",
    "        \"title\": row[\"title\"],\n",
    "        \"description\": row[\"description\"],\n",
    "        \"vector\": row[\"emotion_vector\"],\n",
    "        \"answer\": age_to_group(row[\"age\"])\n",
    "    })\n",
    "\n",
    "models = ['gemma3:1b', 'qwen3:4b']\n",
    "shot_settings = [0, 1, 3, 5]\n",
    "\n",
    "query_rows = examples_csv.sample(5)\n",
    "\n",
    "results = []\n",
    "\n",
    "for _, query_row in query_rows.iterrows():\n",
    "    query_book = query_row[\"title\"]\n",
    "    query_description = query_row[\"description\"]\n",
    "    query_vector = query_row[\"emotion_vector\"]\n",
    "\n",
    "    for model in models:\n",
    "        for n_shots in shot_settings:\n",
    "            examples = random.sample(few_shot_examples, min(n_shots, len(few_shot_examples)))\n",
    "            for i in range(5): #arbitrary number to see any variance in LLM response with the same prompt\n",
    "                prompt = build_prompt(query_book, query_description, query_vector, examples, n_shots)\n",
    "                answer = run_ollama(prompt, model=model)\n",
    "                \n",
    "                results.append({\n",
    "                    \"model\": model,\n",
    "                    \"shots\": n_shots,\n",
    "                    \"book\": query_book,\n",
    "                    \"answer\": answer\n",
    "                })\n",
    "\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(\"ollama_fewshot_results.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
